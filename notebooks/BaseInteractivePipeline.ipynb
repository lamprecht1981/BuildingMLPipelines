{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "mlpipe",
   "display_name": "MLPipeTFX",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1><center>A Basic Interactive Pipeline</center></h1>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 0. Prelim"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 0.1 Moduls"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 0.1.1 Python Moduls"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_analysis as tfma\n",
    "from tfx.components import  (\n",
    "                                CsvExampleGen,\n",
    "                                Evaluator,\n",
    "                                ExampleValidator,\n",
    "                                Pusher,\n",
    "                                ResolverNode,\n",
    "                                SchemaGen,\n",
    "                                StatisticsGen,\n",
    "                                Trainer,\n",
    "                                Transform\n",
    "                            )\n",
    "from tfx.components.base import executor_spec\n",
    "from tfx.components.trainer.executor import GenericExecutor\n",
    "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
    "from tfx.proto import pusher_pb2, trainer_pb2, example_gen_pb2\n",
    "from tfx.types import Channel\n",
    "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
    "from tfx.utils.dsl_utils import external_input"
   ]
  },
  {
   "source": [
    "### 0.1.2 Jupyter Notebooks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 0.2 Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_STEPS = 50000\n",
    "EVAL_STEPS = 10000"
   ]
  },
  {
   "source": [
    "# 1. Init Function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_components(\n",
    "    data_dir,\n",
    "    module_file,\n",
    "    training_steps=TRAIN_STEPS,\n",
    "    eval_steps=EVAL_STEPS,\n",
    "    serving_model_dir=None,\n",
    "    ai_platform_training_args=None,\n",
    "    ai_platform_serving_args=None,\n",
    "):\n",
    "\n",
    "    if serving_model_dir and ai_platform_serving_args:\n",
    "        raise NotImplementedError(\n",
    "            \"Can't set ai_platform_serving_args and serving_model_dir at \"\n",
    "            \"the same time. Choose one deployment option.\"\n",
    "        )\n",
    "\n",
    "    output = example_gen_pb2.Output(\n",
    "        split_config=example_gen_pb2.SplitConfig(\n",
    "            splits=[\n",
    "                example_gen_pb2.SplitConfig.Split(\n",
    "                    name=\"train\", hash_buckets=99\n",
    "                ),\n",
    "                example_gen_pb2.SplitConfig.Split(name=\"eval\", hash_buckets=1),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    examples = external_input(data_dir)\n",
    "    example_gen = CsvExampleGen(input=examples, output_config=output)\n",
    "\n",
    "    statistics_gen = StatisticsGen(examples=example_gen.outputs[\"examples\"])\n",
    "\n",
    "    schema_gen = SchemaGen(\n",
    "        statistics=statistics_gen.outputs[\"statistics\"],\n",
    "        infer_feature_shape=False,\n",
    "    )\n",
    "\n",
    "    example_validator = ExampleValidator(\n",
    "        statistics=statistics_gen.outputs[\"statistics\"],\n",
    "        schema=schema_gen.outputs[\"schema\"],\n",
    "    )\n",
    "\n",
    "    transform = Transform(\n",
    "        examples=example_gen.outputs[\"examples\"],\n",
    "        schema=schema_gen.outputs[\"schema\"],\n",
    "        module_file=module_file,\n",
    "    )\n",
    "\n",
    "    training_kwargs = {\n",
    "        \"module_file\": module_file,\n",
    "        \"examples\": transform.outputs[\"transformed_examples\"],\n",
    "        \"schema\": schema_gen.outputs[\"schema\"],\n",
    "        \"transform_graph\": transform.outputs[\"transform_graph\"],\n",
    "        \"train_args\": trainer_pb2.TrainArgs(num_steps=training_steps),\n",
    "        \"eval_args\": trainer_pb2.EvalArgs(num_steps=eval_steps),\n",
    "    }\n",
    "\n",
    "    if ai_platform_training_args:\n",
    "        from tfx.extensions.google_cloud_ai_platform.trainer import (\n",
    "            executor as aip_trainer_executor,\n",
    "        )\n",
    "\n",
    "        training_kwargs.update(\n",
    "            {\n",
    "                \"custom_executor_spec\": executor_spec.ExecutorClassSpec(\n",
    "                    aip_trainer_executor.GenericExecutor\n",
    "                ),\n",
    "                \"custom_config\": {\n",
    "                    aip_trainer_executor.TRAINING_ARGS_KEY: ai_platform_training_args  # noqa\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        training_kwargs.update(\n",
    "            {\n",
    "                \"custom_executor_spec\": executor_spec.ExecutorClassSpec(\n",
    "                    GenericExecutor\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "    trainer = Trainer(**training_kwargs)\n",
    "\n",
    "    model_resolver = ResolverNode(\n",
    "        instance_name=\"latest_blessed_model_resolver\",\n",
    "        resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n",
    "        model=Channel(type=Model),\n",
    "        model_blessing=Channel(type=ModelBlessing),\n",
    "    )\n",
    "\n",
    "    eval_config = tfma.EvalConfig(\n",
    "        model_specs=[tfma.ModelSpec(label_key=\"consumer_disputed\")],\n",
    "        slicing_specs=[\n",
    "            tfma.SlicingSpec(),\n",
    "            tfma.SlicingSpec(feature_keys=[\"product\"]),\n",
    "        ],\n",
    "        metrics_specs=[\n",
    "            tfma.MetricsSpec(\n",
    "                metrics=[\n",
    "                    tfma.MetricConfig(class_name=\"BinaryAccuracy\"),\n",
    "                    tfma.MetricConfig(class_name=\"ExampleCount\"),\n",
    "                    tfma.MetricConfig(class_name=\"AUC\"),\n",
    "                ],\n",
    "                thresholds={\n",
    "                    \"AUC\": tfma.config.MetricThreshold(\n",
    "                        value_threshold=tfma.GenericValueThreshold(\n",
    "                            lower_bound={\"value\": 0.65}\n",
    "                        ),\n",
    "                        change_threshold=tfma.GenericChangeThreshold(\n",
    "                            direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                            absolute={\"value\": 0.01},\n",
    "                        ),\n",
    "                    )\n",
    "                },\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    evaluator = Evaluator(\n",
    "        examples=example_gen.outputs[\"examples\"],\n",
    "        model=trainer.outputs[\"model\"],\n",
    "        baseline_model=model_resolver.outputs[\"model\"],\n",
    "        eval_config=eval_config,\n",
    "    )\n",
    "\n",
    "    pusher_kwargs = {\n",
    "        \"model\": trainer.outputs[\"model\"],\n",
    "        \"model_blessing\": evaluator.outputs[\"blessing\"],\n",
    "    }\n",
    "\n",
    "    if ai_platform_serving_args:\n",
    "        from tfx.extensions.google_cloud_ai_platform.pusher import (\n",
    "            executor as aip_pusher_executor,\n",
    "        )\n",
    "\n",
    "        pusher_kwargs.update(\n",
    "            {\n",
    "                \"custom_executor_spec\": executor_spec.ExecutorClassSpec(\n",
    "                    aip_pusher_executor.Executor\n",
    "                ),\n",
    "                \"custom_config\": {\n",
    "                    aip_pusher_executor.SERVING_ARGS_KEY: ai_platform_serving_args  # noqa\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    elif serving_model_dir:\n",
    "        pusher_kwargs.update(\n",
    "            {\n",
    "                \"push_destination\": pusher_pb2.PushDestination(\n",
    "                    filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "                        base_directory=serving_model_dir\n",
    "                    )\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"Provide ai_platform_serving_args or serving_model_dir.\"\n",
    "        )\n",
    "\n",
    "    pusher = Pusher(**pusher_kwargs)\n",
    "\n",
    "    components = [\n",
    "        example_gen,\n",
    "        statistics_gen,\n",
    "        schema_gen,\n",
    "        example_validator,\n",
    "        transform,\n",
    "        trainer,\n",
    "        model_resolver,\n",
    "        evaluator,\n",
    "        pusher,\n",
    "    ]\n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}